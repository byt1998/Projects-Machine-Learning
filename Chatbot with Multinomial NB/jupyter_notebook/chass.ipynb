{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Introduction\n",
    "\n",
    "**Made by  :** \n",
    "  - Enggar Kristian \n",
    "  - Wahyudi\n",
    "\n",
    "**Batch : FTDS - 012** \n",
    "\n",
    "**Objective : Final project, model Machine Learning for chatbot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library that will be used in this project\n",
    "\n",
    "# Library for Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Library for preprocessing\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# Library for modelling\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pickle\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from util import JSONParser\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Library for model evaluation\n",
    "from sklearn import metrics\n",
    "\n",
    "# import for verification Name, email, and OTP\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from folders\n",
    "path = \"D:\\Bootcamp Data Science Batch 011 - Hacktiv8\\Final Project\\p2---final-project-ftds-012-group-003\\jupyter_notebook\\data\\intents.json\"\n",
    "\n",
    "# Defining JSONParser\n",
    "jp = JSONParser()\n",
    "\n",
    "# Parsing data intents\n",
    "jp.parse(path)\n",
    "\n",
    "# Building dataframe and save it to variable df\n",
    "df = jp.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'tag': 'salam', 'patterns': ['Hai', 'Halo', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'tag': 'menindaklanjuti', 'patterns': ['Dah',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'tag': 'penutup', 'patterns': ['penutup', 'ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'tag': 'tugas', 'patterns': ['Fungsi kamu nga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'tag': 'daftar akun', 'patterns': ['Daftar ak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'tag': 'verifikasi', 'patterns': ['Verifikasi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'tag': 'unduh aplikasi', 'patterns': ['Downlo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'tag': 'biaya', 'patterns': ['Biaya?', 'Biaya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'tag': 'atm', 'patterns': ['ATM', 'Buat ATM',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'tag': 'ganti ATM', 'patterns': ['ATM rusak',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'tag': 'lokasi', 'patterns': ['Kantor', 'Loka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'tag': 'website', 'patterns': ['website', 'we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              intents\n",
       "0   {'tag': 'salam', 'patterns': ['Hai', 'Halo', '...\n",
       "1   {'tag': 'menindaklanjuti', 'patterns': ['Dah',...\n",
       "2   {'tag': 'penutup', 'patterns': ['penutup', 'ga...\n",
       "3   {'tag': 'tugas', 'patterns': ['Fungsi kamu nga...\n",
       "4   {'tag': 'daftar akun', 'patterns': ['Daftar ak...\n",
       "5   {'tag': 'verifikasi', 'patterns': ['Verifikasi...\n",
       "6   {'tag': 'unduh aplikasi', 'patterns': ['Downlo...\n",
       "7   {'tag': 'biaya', 'patterns': ['Biaya?', 'Biaya...\n",
       "8   {'tag': 'atm', 'patterns': ['ATM', 'Buat ATM',...\n",
       "9   {'tag': 'ganti ATM', 'patterns': ['ATM rusak',...\n",
       "10  {'tag': 'lokasi', 'patterns': ['Kantor', 'Loka...\n",
       "11  {'tag': 'website', 'patterns': ['website', 'we..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_json('D:\\Bootcamp Data Science Batch 011 - Hacktiv8\\Final Project\\p2---final-project-ftds-012-group-003\\jupyter_notebook\\data\\intents.json')\n",
    "df1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data intents.json made by us for conversation between costumer and chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chat_input</th>\n",
       "      <th>intents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hai</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Halo</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>helo</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hei</td>\n",
       "      <td>salam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>bisa akses dimana</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>info lengkap perusahaan dimana min?</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>apakah ada webnya</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>profile bank nya dimana ya?</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>spill websitenya kak?</td>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              chat_input  intents\n",
       "0                                    Hai    salam\n",
       "1                                   Halo    salam\n",
       "2                                  Hello    salam\n",
       "3                                   helo    salam\n",
       "4                                    Hei    salam\n",
       "..                                   ...      ...\n",
       "535                    bisa akses dimana  website\n",
       "536  info lengkap perusahaan dimana min?  website\n",
       "537                    apakah ada webnya  website\n",
       "538          profile bank nya dimana ya?  website\n",
       "539                spill websitenya kak?  website\n",
       "\n",
       "[540 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dekat'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look into sample chat\n",
    "sample_chat = df.chat_input[430]\n",
    "sample_chat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dekat'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming the chat into lowercase\n",
    "chat_lower = sample_chat.lower()\n",
    "chat_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dekat'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Remove punctuations from the chat\n",
    "chat_punct = chat_lower.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "chat_punct\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dekat'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to change non-alphabetical characters with spaces too to make the data cleaner.\n",
    "chat_punct = re.sub(\"[^A-Za-z\\s']\",\" \", chat_punct)\n",
    "chat_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dekat'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove tab, in case the customer is mistype inputting tab on their chat\n",
    "chat_punct = chat_punct.strip()\n",
    "chat_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dekat'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining Stemmer\n",
    "stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "# Applying stemmer to the chat\n",
    "output   = stemmer.stem(chat_punct)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to case folding corpus in the dataframe\n",
    "def document_processing(document):\n",
    "    # Transform Document Into Lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Remove Punctuation From Document\n",
    "    document = document.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "\n",
    "    # Remove Digit From Document\n",
    "    document = re.sub(\"[^A-Za-z\\s']\",\" \", document)\n",
    "\n",
    "    # Remove links\n",
    "    document = re.sub(r'http\\S+', '', document) # remove links\n",
    "    document = re.sub(r\"www.\\S+\", \" \", document) # remove link\n",
    "    \n",
    "    # Remove Tab From Document\n",
    "    document = document.strip()\n",
    "\n",
    "    #Stemmer\n",
    "    stemmer = StemmerFactory().create_stemmer()\n",
    "\n",
    "    # stemming process\n",
    "    document = stemmer.stem(document)\n",
    "\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make function for subtitute all equation for cleaning data text, and stemming. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split between data (X) and target (y)\n",
    "X = df.chat_input\n",
    "y = df.intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Preprocessing text with Case Folding Function\n",
    "X_proc = X.apply(document_processing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply function cleaning text to the data set, and apply to all string. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define text Vectorizer\n",
    "vect = CountVectorizer()\n",
    "vect.fit(X_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Vectorization from scikit learn use to convert string to integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set shape      : (432, 432)\n",
      "Test-Set shape       : (108, 108)\n"
     ]
    }
   ],
   "source": [
    "# Split Data for Train-Set and Test-Set\n",
    "X_train, X_test,  y_train, y_test = train_test_split(X_proc, y,test_size=0.2, random_state=5)\n",
    "print(f\"Train-Set shape      : {len(X_train),len(y_train)}\")\n",
    "print(f\"Test-Set shape       : {len(X_test),len(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultinomialNB Pipeline\n",
    "nb = make_pipeline(CountVectorizer(),\n",
    "                   MultinomialNB())\n",
    "\n",
    "# Training\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define with model machine learning Multinomial Naive Bayes with pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Enggar\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:43] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                ('xgbclassifier',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,\n",
       "                               gamma=0, gpu_id=-1, importance_type=None,\n",
       "                               interaction_constraints='', learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=2,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=60,\n",
       "                               n_jobs=4, num_parallel_tree=1,\n",
       "                               objective='multi:softprob', predictor='auto',\n",
       "                               random_state=5, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=None, subsample=1,\n",
       "                               tree_method='exact', validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Pipeline\n",
    "xgb = make_pipeline(CountVectorizer(),\n",
    "                   XGBClassifier(random_state=5, learning_rate=0.1, max_depth=2, n_estimators=60))\n",
    "\n",
    "# Training\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of our favourite model Machine Learning that is Extreme Gradient Boosting. Uprgade from ensemble learning and latest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                ('decisiontreeclassifier', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Pipeline\n",
    "dt = make_pipeline(CountVectorizer(),\n",
    "                   DecisionTreeClassifier())\n",
    "\n",
    "# Training\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make pipeline model Decision Tree for eficiency running time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation for MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set Multinomial Naive Bayes model accuracy(in %): 94.44444444444444\n",
      "Test-Set Multinomial Naive Bayes model accuracy(in %) : 82.4074074074074\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_nb = nb.predict(X_train)\n",
    "y_test_pred_nb = nb.predict(X_test)\n",
    "print(\"Train-Set Multinomial Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_train_pred_nb, y_train)*100)\n",
    "print(\"Test-Set Multinomial Naive Bayes model accuracy(in %) :\", metrics.accuracy_score(y_test_pred_nb, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a great result, from a dataset that is not much but the MultinomialNB model can read it well, so that it gets optimal results for the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set Decision Tree model accuracy(in %): 99.30555555555556\n",
      "Test-Set Decision Tree model accuracy(in %) : 70.37037037037037\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_dt = dt.predict(X_train)\n",
    "y_test_pred_dt = dt.predict(X_test)\n",
    "print(\"Train-Set Decision Tree model accuracy(in %):\", metrics.accuracy_score(y_train_pred_dt, y_train)*100)\n",
    "print(\"Test-Set Decision Tree model accuracy(in %) :\", metrics.accuracy_score(y_test_pred_dt, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree is not better than the MultinomialNB model, we can see that the model brings overfit results and is far below MultinomialNB for the test data results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Set Random Forest model accuracy(in %): 73.61111111111111\n",
      "Test-Set Random Forest model accuracy(in %) : 62.96296296296296\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_xgb = xgb.predict(X_train)\n",
    "y_test_pred_xgb = xgb.predict(X_test)\n",
    "print(\"Train-Set Random Forest model accuracy(in %):\", metrics.accuracy_score(y_train_pred_xgb, y_train)*100)\n",
    "print(\"Test-Set Random Forest model accuracy(in %) :\", metrics.accuracy_score(y_test_pred_xgb, y_test)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oops, the favorite model actually doesn't study the text data model well, the results are the worst among the other 2 models, but goodfit, the data inference will not use the XGBoost model later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 - Model Saving\n",
    "\n",
    "Well, in the end, based on the results, we chose the MultinomialNB model to be a machine learning model that will be applied to chatbots in the banking industry, to add and satisfy service to customers who have complaints on Twitter later, then this chatbot will be active if customers chat via Direct Message on our official account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Saving Random Forest\n",
    "with open('model_2.pkl', 'wb') as file:\n",
    "  pickle.dump(nb, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Building Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hai kakak, saat ini kamu tehubung dengan akun bisnis resmi Bank T0yip. Pesan ini akan dibalas oleh Costumer Handler Assitant atau kamu bisa panggil Chass :)\n",
      "Saya : kalo ganti atm bisa ga?\n",
      "Bot  : Halo kak! mau ganti ATM yaaa, boleh banget sini Chass bantu hehehe. Oke kaka bisa banget ganti kartu untuk kartu ATM rusak, kartu ATM tertelan, dan kartu ATM hilang dengan mengujungi lokasi kantor cabang terdekat atau sama aku nanti aku bantu sepenuhnya, namun akan dikenakan biaya tambahan untuk materai 10000 sebesar Rp10.000 pembayarannya akan otomatis dipotong melalui kartu bank untuk penggantian kartu lama dengan kartu yang baru, kakak cukup ketik #gantiATM untuk melanjutkan proses penggantiannya.\n",
      "\n",
      "Saya : #gantiATM\n",
      "Baik kak aku bantu proses pergantian ATM ya, Sebelumnya ada beberapa syarat yang harus dilengkapi yaitu dengan isi data diri berikut:\n",
      "Masukkan nama lengkap Anda: \n",
      "enggar kristian\n",
      "\n",
      "Masukkan email Anda:\n",
      "enggarkristian@gmail.com\n",
      "\n",
      "Masukkan nomor handphone Anda:\n",
      "087786112081\n",
      "\n",
      "Masukkan nomor rekening Anda: \n",
      "32750327059800150660822283\n",
      "\n",
      "HATI-HATI PENIPUAN! JANGAN BERIKAN OTP ke siapapun \n",
      "Kode OTP Anda: 7255. Silakan gunakan untuk melanjutkan proses transaksi.\n",
      "\n",
      "Masukkan 4 digit kode OTP Anda: \n",
      "7255\n",
      "\n",
      "Selamat kakak akan menerima kartu ATM baru! \n",
      "Tunggu verfikasi dari kami ya kak maksimal 30 menit, verifikasi dikirim lewat email kakak, dan jika sudah terverifikasi dengan kami makan akan kami kirim maksimal 3x24 jam kartu ATM baru kakak sampai rumah. \n",
      "Jika ada yang ingin ditanyakan lagi jangan sungkan bertanya ya kak.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Hai kakak, saat ini kamu tehubung dengan akun bisnis resmi Bank T0yip. Pesan ini akan dibalas oleh Costumer Handler Assitant atau kamu bisa panggil Chass :)\")\n",
    "while True:\n",
    "    # input user\n",
    "    chat = input(\"Saya : \")\n",
    "    # Preprocessing\n",
    "    chat_processed = document_processing(chat)\n",
    "    # Intent prediction (tag)\n",
    "    res = nb.predict_proba([chat_processed])\n",
    "    # get the probability value and its location\n",
    "    max_prob = max(res[0])\n",
    "    max_idx = np.argmax(res[0])\n",
    "    \n",
    "    print(\"Saya :\",chat)\n",
    "    # Define solving #gantiATm\n",
    "    if chat == '#gantiATM':\n",
    "        print(\"Baik kak aku bantu proses pergantian ATM ya, Sebelumnya ada beberapa syarat yang harus dilengkapi yaitu dengan isi data diri berikut:\")\n",
    "        print(\"Masukkan nama lengkap Anda: \")\n",
    "        while True:\n",
    "            nama = input(\"Nama:\")\n",
    "            if len(nama) <= 1:\n",
    "                print(\"Kolom nama tidak boleh kosong.\")\n",
    "            else:\n",
    "                print(nama)\n",
    "                print(\"\\nMasukkan email Anda:\")\n",
    "                break\n",
    "        while True:\n",
    "            Email = input(\"Email: \")\n",
    "            if \"@\" not in Email:\n",
    "                print(\"Email anda salah tidak ada '@' di dalamnya\\n\")\n",
    "            elif \".\" not in Email:\n",
    "                print(\"Email anda salah tidak ada '.' di dalamnya\\n\")\n",
    "            else:\n",
    "                print(Email)    \n",
    "                print(\"\\nMasukkan nomor handphone Anda:\")\n",
    "                break    \n",
    "        no_hp = int(input(\"Nomor handphone: \"))\n",
    "        print(f\"0{no_hp}\")\n",
    "        print(\"\\nMasukkan nomor rekening Anda: \")\n",
    "        while True:\n",
    "            no_rek = input(\"Nomor rekekning minimal 10 digit: \")\n",
    "            if len(no_rek) <= 8:\n",
    "                print(\"Nomor rekening Anda salah!\")\n",
    "            else:\n",
    "                print(no_rek)\n",
    "                break\n",
    "        no_otp = no_rek\n",
    "        while True:\n",
    "            # Define random OTP code\n",
    "            OTP=\"\"\n",
    "            for i in range(4):\n",
    "                OTP+=no_otp[math.floor(random.random()*10)]\n",
    "            else:\n",
    "                print(f\"\\nHATI-HATI PENIPUAN! JANGAN BERIKAN OTP ke siapapun \\nKode OTP Anda: {OTP}. Silakan gunakan untuk melanjutkan proses transaksi.\\n\") \n",
    "                print(\"Masukkan 4 digit kode OTP Anda: \")\n",
    "            while True:    \n",
    "                input_otp = input(\"\\nKode OTP 4 digit: \")\n",
    "                if input_otp != OTP:\n",
    "                    print(f\"Kode OTP yang Anda masukkan salah!\")\n",
    "                else:\n",
    "                    print(input_otp)\n",
    "                    print(\"\\nSelamat kakak akan menerima kartu ATM baru! \\nTunggu verfikasi dari kami ya kak maksimal 30 menit, verifikasi dikirim lewat email kakak, dan jika sudah terverifikasi dengan kami makan akan kami kirim maksimal 3x24 jam kartu ATM baru kakak sampai rumah. \\nJika ada yang ingin ditanyakan lagi jangan sungkan bertanya ya kak.\\n\")\n",
    "                    break\n",
    "                \n",
    "            break\n",
    "    # Define condition for unknown input\n",
    "    elif max_prob < 0.20:\n",
    "        print(\"Bot  : Maaf Kak, aku masih gak ngerti maksud kakak\")\n",
    "    # Define condition to give response towards specific tag\n",
    "    else:\n",
    "        print(f\"Bot  : {jp.get_response(nb.classes_[max_idx])}\\n\")\n",
    "\n",
    "    # Define response to end the chat for tag \"penutup\"\n",
    "    if nb.classes_[max_idx] == 'penutup':\n",
    "        break\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has successfully made, and can apply to API Twitter Direct Message!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3313081f939a1cd2fc9e524e93ad175a39774b1d821a5d0f007e3e4c61533bad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
